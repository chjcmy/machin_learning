# 선형 회귀(Linear Regression) 기초 상세 가이드

이 가이드는 `D1_01_linear_regression_basics_GD2601.ipynb` 노트북의 각 단계를 초보자 눈높이에서 "왜 하는지", "무엇이 중요한지", "어디를 봐야 하는지"로 정리했습니다.

---

## 1. 라이브러리 임포트 (Libraries)
```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
```

### 1) 왜 하는가? (Why)
- **도구상자 준비**: 파이썬은 기본 기능만으로는 수학 계산이나 그래프 그리기가 어렵습니다. 그래서 전문가들이 만들어둔 도구를 가져옵니다.
- `numpy`: 숫자 계산기.
- `matplotlib`: 그래프 그리기 도구.
- `sklearn` (사이킷런): 머신러닝 모델(선형회귀 등)이 들어있는 핵심 도구상자입니다.

### 2) 무엇이 중요한가? (Key Point)
- `LinearRegression`: 우리가 사용할 모델입니다. 데이터를 보고 직선(y = ax + b)을 긋는 역할을 합니다.

### 3) 무엇을 봐야 하는가? (Focus)
- 에러 없이 실행되는지 확인하세요.

---

## 2. 인공 데이터 생성 (Data Generation)
```python
X = 2 * np.random.rand(200, 1)
y = 3 * X + 5 + noise
```

### 1) 왜 하는가? (Why)
- 공부할 **문제집 만들기**: 실제 데이터를 구하기 전에, 우리가 정답(규칙)을 알고 있는 데이터를 만들어서 모델이 잘 맞추는지 테스트해보는 것입니다.
- `y = 3x + 5`: 우리가 정한 **진짜 규칙**입니다. (기울기 3, 절편 5). 모델이 이 숫자 3과 5를 찾아내야 합니다.
- `noise`: 현실 세계의 데이터는 완벽하지 않고 오차가 있기 때문에, 일부러 잡음(noise)을 섞어줍니다.

### 2) 무엇이 중요한가? (Key Point)
- `np.random.seed(42)`: 랜덤이지만 **항상 똑같은 랜덤**이 나오게 고정합니다. 그래야 선생님(저)과 학생(여러분)의 결과가 똑같이 나옵니다.

### 3) 무엇을 봐야 하는가? (Focus)
- `X`(문제)와 `y`(정답)가 만들어졌다는 것만 알면 됩니다.

---

## 3. 데이터 분할 (Train/Test Split)
```python
X_train, X_test, y_train, y_test = train_test_split(..., test_size=0.2)
```

### 1) 왜 하는가? (Why)
- **컨닝 방지**: 모델에게 100문제를 다 보여주고 시험을 치면, 답을 외워서 100점을 맞을 수도 있습니다.
- 그래서 80문제(`Train`)는 공부용으로 주고, 20문제(`Test`)는 숨겨뒀다가 나중에 "진짜 실력"을 테스트할 때 씁니다.

### 2) 무엇이 중요한가? (Key Point)
- `test_size=0.2`: 20%를 시험 문제로 빼둔다는 뜻입니다.

### 3) 무엇을 봐야 하는가? (Focus)
- 데이터가 4조각(`X_train`, `X_test`, `y_train`, `y_test`)으로 나뉘었다는 점을 기억하세요.

---

## 4. 모델 학습 (Training)
```python
model = LinearRegression()
model.fit(X_train, y_train)
```

### 1) 왜 하는가? (Why)
- **공부 시키기**: 모델(학생)에게 공부용 문제(`X_train`)와 정답(`y_train`)을 줍니다.
- `fit`: "이 데이터를 보고 규칙(기울기와 절편)을 찾아내라!"고 명령하는 것입니다.

### 2) 무엇이 중요한가? (Key Point)
- `fit()` 함수 한 줄이면 학습이 끝납니다.
- 모델은 내부적으로 수많은 계산을 해서 오차가 가장 적은 선을 찾습니다.

### 3) 무엇을 봐야 하는가? (Focus)
- `model.coef_`: 모델이 찾아낸 **기울기**입니다. (우리가 만든 정답 3에 가까워야 합니다.)
- `model.intercept_`: 모델이 찾아낸 **절편**입니다. (우리가 만든 정답 5에 가까워야 합니다.)

---

## 5. 예측 및 평가 (Prediction & Evaluation)
```python
y_pred = model.predict(X_test)
mean_squared_error(y_test, y_pred)
```

### 1) 왜 하는가? (Why)
- **시험 치기 및 채점**: 숨겨둔 문제(`X_test`)를 풀게 하고(`predict`), 진짜 정답(`y_test`)과 비교해서 점수를 매깁니다.

### 2) 무엇이 중요한가? (Key Point)
- `MSE` (평균 제곱 오차): 틀린 정도의 평균입니다. **0에 가까울수록 좋습니다.**
- `R^2` (결정 계수): 100점 만점에 몇 점인지와 비슷합니다. **1에 가까울수록 완벽한 모델**입니다.

### 3) 무엇을 봐야 하는가? (Focus)
- `Test R^2`가 0.9 이상이면 아주 훌륭하게 학습한 것입니다.

---

## 6. 시각화 (Visualization)
```python
plt.scatter(...)
plt.plot(...)
```

### 1) 왜 하는가? (Why)
- **눈으로 확인하기**: 숫자로만 보면 감이 안 오니까, 점(데이터)과 선(모델이 찾은 규칙)을 그래프로 그려서 잘 맞는지 확인합니다.

### 2) 무엇이 중요한가? (Key Point)
- 파란 점(학습 데이터)과 주황 점(테스트 데이터) 사이를 빨간 선(회귀선)이 잘 관통하고 있는지 봅니다.

### 3) 무엇을 봐야 하는가? (Focus)
- **잔차 그래프(Residual Plot)**: 예측값과 실제값의 차이를 그린 그래프입니다. 0을 기준으로 무작위로 퍼져있어야 좋은 모델입니다. 만약 어떤 패턴(곡선 등)이 보이면, 모델이 뭔가 놓치고 있다는 뜻입니다.
